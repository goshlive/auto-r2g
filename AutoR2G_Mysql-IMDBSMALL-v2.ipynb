{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2eedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import csv\n",
    "import re\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.errors import ParserError\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc03eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'relational.fel.cvut.cz'\n",
    "schema = 'imdb_small'\n",
    "user = 'guest'\n",
    "password = 'ctu-relational'\n",
    "neo_uri='bolt://localhost:7687'\n",
    "neo_user='neo4j'\n",
    "neo_pass='P@SSw0rd'\n",
    "neo_db='imdbsmall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b20b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'imdbsmall' already exists.\n",
      "Switched to database 'imdbsmall' as the default.\n"
     ]
    }
   ],
   "source": [
    "class Neo4jDB:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd='', default_db=None):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        self.__default_db = default_db\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "            if self.__default_db:\n",
    "                self.ensure_database(self.__default_db)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None):\n",
    "        \"\"\"Executes a query on the default database.\"\"\"\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        assert self.__default_db is not None, \"Default database not set!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try:\n",
    "            session = self.__driver.session(database=self.__default_db)\n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response\n",
    "\n",
    "    def ensure_database(self, db_name):\n",
    "        \"\"\"Ensures the specified database exists and sets it as the default.\"\"\"\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        try:\n",
    "            session = self.__driver.session(database=\"system\")\n",
    "            # Check if the database exists\n",
    "            existing_databases = [record[\"name\"] for record in session.run(\"SHOW DATABASES\")]\n",
    "            if db_name not in existing_databases:\n",
    "                session.run(f\"CREATE DATABASE {db_name}\")\n",
    "                print(f\"Database '{db_name}' created successfully.\")\n",
    "            else:\n",
    "                print(f\"Database '{db_name}' already exists.\")\n",
    "            \n",
    "            # Verify that the database exists\n",
    "            existing_databases = [record[\"name\"] for record in session.run(\"SHOW DATABASES\")]\n",
    "            if db_name in existing_databases:\n",
    "                self.__default_db = db_name\n",
    "                print(f\"Switched to database '{db_name}' as the default.\")\n",
    "            else:\n",
    "                raise Exception(f\"Database '{db_name}' could not be verified after creation.\")\n",
    "        except Exception as e:\n",
    "            print(\"Failed to ensure database existence or switch to it:\", e)\n",
    "        finally:\n",
    "            if session is not None:\n",
    "                session.close()\n",
    "\n",
    "neoConn = Neo4jDB(uri=neo_uri, user=neo_user, pwd=neo_pass, default_db=neo_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beac3407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL Server version  5.5.5-10.6.12-MariaDB-1:10.6.12+maria~ubu2004-log\n",
      "You're connected to database:  ('imdb_small',)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    connection = mysql.connector.connect(host=host, database=schema, user=user, password=password)\n",
    "    \n",
    "    if connection.is_connected():\n",
    "        db_Info = connection.get_server_info()\n",
    "        print(\"Connected to MySQL Server version \", db_Info)\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81121343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clear_all(commit):\n",
    "    if commit:\n",
    "        query='''MATCH (n)\n",
    "        DETACH DELETE n\n",
    "        RETURN count(*) AS total'''\n",
    "        return neoConn.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896b893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(tables, keys):\n",
    "    ref = {}\n",
    "    for i in range(len(tables)):\n",
    "        table = tables[i]\n",
    "        if ref.get(table):\n",
    "            ref[table] += ','+str(keys[i])\n",
    "        else:\n",
    "            ref[table] = str(keys[i])\n",
    "    \n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9380b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_obj(name, df, excludes):\n",
    "    header = list(df.columns)\n",
    "    \n",
    "    obj = '('+name.lower()+':'+name.capitalize()+'{'\n",
    "    first = True\n",
    "    for h in header:\n",
    "        if h not in excludes:\n",
    "            if first:\n",
    "                first = False\n",
    "            else:\n",
    "                obj +=','\n",
    "            obj += h+': row.'+h\n",
    "        \n",
    "    obj +='})'\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6d54175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_csv(table, s, e):\n",
    "    file = 'db.localhost/{}/{}.csv'.format(schema, table)\n",
    "    #print(\"file: {}\".format(file))\n",
    "    return pd.read_csv (file, sep = s, encoding = e)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0b4a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ref_node(table, ref_table):\n",
    "    #print(\"table:{}, ref_table:{}\".format(table, ref_table))\n",
    "    rtn = ref_table.lower()\n",
    "    if table and ref_table:\n",
    "        if table.strip() == ref_table.strip():\n",
    "            return \"{}_\".format(ref_table.lower())\n",
    "            \n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb047101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_graph(m, df_logs, commit):\n",
    "    st = time.time()\n",
    "    table = m.get('table')    \n",
    "    print(\"\\n\\n===> Processing records for Table '{}'\".format(table))\n",
    "    if not commit:\n",
    "        print(m)    \n",
    "\n",
    "    records = _read_csv(table, ';', 'utf-8')\n",
    "    #print(f'records: {records}')\n",
    "\n",
    "    query = '''UNWIND $rows AS row \\nCREATE ''' + populate_obj(table.lower(), records, []) + '''\\nRETURN count(*) as total'''\n",
    "\n",
    "    df_logs = _add_row(df_logs, table, ref_tables='', no_records=len(records), no_rels=0, no_nodes=1)\n",
    "    \n",
    "    if not commit:\n",
    "        print(query)\n",
    "    else:\n",
    "        neoConn.query(query, parameters = {'rows': records.to_dict('records')})\n",
    "        \n",
    "    return df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c38ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joined_graph(m, s, df_logs, commit):\n",
    "    table = m.get('table')\n",
    "    print(\"\\n\\n===> Processing records for Table '{}'\".format(table))\n",
    "    if not commit:\n",
    "        print(m)    \n",
    "\n",
    "    records = _read_csv(table, ';', 'utf-8')\n",
    "\n",
    "    pri_key = m.get('pri_key').split(',')    \n",
    "    for_keys = m.get('for_keys').split(',')    \n",
    "    # print(for_keys)\n",
    "    ref_tables = m.get('ref_tables').split(',')  \n",
    "    # print(ref_tables)\n",
    "    ref_keys = m.get('ref_keys').split(',')    \n",
    "    # print(ref_keys)\n",
    "    ref = get_dict(ref_tables, ref_keys)\n",
    "    # print(ref)\n",
    "    \n",
    "    #if sorted(pri_key) == sorted(for_keys):\n",
    "    #    query = '''UNWIND $rows AS row\\nCREATE ''' + populate_obj(table.lower(), records, []) +'''\\n'''\n",
    "    #else:\n",
    "    #    query = '''UNWIND $rows AS row\\nCREATE ''' + populate_obj(table.lower(), records, for_keys) +'''\\n'''    \n",
    "    #include ids\n",
    "    query = '''UNWIND $rows AS row\\nCREATE ''' + populate_obj(table.lower(), records, []) +'''\\n'''\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    no_edges = 0\n",
    "    for ref_table, ids in ref.items():\n",
    "        \n",
    "        ref_ids = ids.split(',')\n",
    "        # print(ref_table)\n",
    "        # print(ref_ids)\n",
    "\n",
    "        end = start+len(ref_ids)\n",
    "        fk = for_keys[start:end]\n",
    "\n",
    "        #skip, if it is a cyclic table\n",
    "        if s and ref_table in s:\n",
    "            print(\"********** Table '{}' is a cyclic referenced by Table '{}'..skipped it *********\".format(ref_table, table))\n",
    "            start = end\n",
    "            continue\n",
    "        \n",
    "        print(\"Processing reference Table '{}' ...\".format(ref_table))\n",
    "        query += '''\\nWITH distinct row, ''' + table.lower()\n",
    "        \n",
    "        no_edges += 1\n",
    "        \n",
    "        prev_fk = None\n",
    "        duplicate = False\n",
    "        uwind = {}\n",
    "        for i in range(len(fk)):\n",
    "            if (prev_fk == ref_ids[i]):\n",
    "                uwind[i] = '''\\nUNWIND row.''' + fk[i] + ''' AS _''' + fk[i]\n",
    "            else:\n",
    "                query += '''\\nUNWIND row.''' + fk[i] + ''' AS _''' + fk[i]\n",
    "            prev_fk = ref_ids[i]\n",
    "\n",
    "        if len(uwind) > 0:\n",
    "            for i in range(len(fk)):\n",
    "                if i>0:\n",
    "                    query += '''\\nWITH distinct row, ''' + table.lower()\n",
    "                    query += uwind.get(i)\n",
    "                ref = _get_ref_node(table, ref_table)\n",
    "                query += '''\\nMATCH (''' +ref+ ''':'''+ ref_table.capitalize() +''' {'''\n",
    "                query += ref_ids[i] + ''': _'''+fk[i]\n",
    "                query += '''})\\nMERGE ('''+table.lower()+''')-[:'''+ table.upper() + '''_''' + ref_table.upper() +''']->('''+ref+''')'''\n",
    "        else:\n",
    "            ref = _get_ref_node(table, ref_table)\n",
    "            query += '''\\nMATCH (''' + ref + ''':'''+ ref_table.capitalize() +''' {'''\n",
    "            first = True\n",
    "            for i in range(len(fk)):\n",
    "                if not first:\n",
    "                    query += ''','''\n",
    "                else:\n",
    "                    first = False\n",
    "                query += ref_ids[i] + ''': _'''+fk[i]\n",
    "            query += '''})\\nMERGE ('''+table.lower()+''')-[:'''+ table.upper() + '''_''' + ref_table.upper() +''']->('''+ref+''')'''\n",
    "\n",
    "        start = end\n",
    "\n",
    "    query += '''\\nRETURN count(*) AS total'''\n",
    "\n",
    "    df_logs = _add_row(df_logs, table, ref_tables=ref_tables, no_records=len(records), no_rels=len(ref_tables), no_nodes=1, no_edges=no_edges)\n",
    "    \n",
    "    if not commit:\n",
    "        print(query)\n",
    "    else:\n",
    "        neoConn.query(query, parameters = {'rows': records.to_dict('records')})    \n",
    "        \n",
    "    return df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e34aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edges(m, r, df_logs, commit):\n",
    "    table = m.get('table')\n",
    "    print(\"\\n\\n===> Creating additional Edges between Table '{}' and Table(s) '{}' \".format(table, r))\n",
    "    if not commit:\n",
    "        print(m)\n",
    "        print(r)\n",
    "\n",
    "    records = _read_csv(table, ';', 'utf-8')\n",
    "\n",
    "    pri_key = m.get('pri_key').split(',')    \n",
    "    for_keys = m.get('for_keys').split(',')    \n",
    "    # print(for_keys)\n",
    "    ref_tables = m.get('ref_tables').split(',')  \n",
    "    # print(ref_tables)\n",
    "    ref_keys = m.get('ref_keys').split(',')    \n",
    "    # print(ref_keys)\n",
    "    ref = get_dict(ref_tables, ref_keys)\n",
    "    # print(ref)\n",
    "    \n",
    "    query = '''UNWIND $rows AS row'''\n",
    "    for prim in pri_key:\n",
    "        query += '''\\nUNWIND row.''' + prim + ''' AS _''' + prim\n",
    "    \n",
    "    query += '''\\nMATCH (''' + table.lower() + ''':'''+ table.capitalize() +''' {'''\n",
    "    first = True\n",
    "    for i in range(len(pri_key)):\n",
    "        if not first:\n",
    "            query += ''','''\n",
    "        else:\n",
    "            first = False\n",
    "        query += pri_key[i] + ''': _'''+pri_key[i]\n",
    "    query += '''})'''\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    no_edges = 0\n",
    "    for ref_table, ids in ref.items():\n",
    "        \n",
    "        ref_ids = ids.split(',')\n",
    "        #print(ref_table)\n",
    "        #print(ref_ids)\n",
    "\n",
    "        end = start+len(ref_ids)\n",
    "        fk = for_keys[start:end]\n",
    "        \n",
    "        if ref_table not in r:\n",
    "            print('********** Skipping table {} **********'.format(ref_table))\n",
    "            start = end\n",
    "            continue\n",
    "                \n",
    "        print(\"Creating an Edge from Table '{}' --> Table '{}' ...\".format(table, ref_table))\n",
    "        query += '''\\nWITH distinct row, ''' + table.lower()\n",
    "        \n",
    "        no_edges += 1\n",
    "        \n",
    "        prev_fk = None\n",
    "        duplicate = False\n",
    "        uwind = {}\n",
    "        for i in range(len(fk)):\n",
    "            if (prev_fk == ref_ids[i]):\n",
    "                uwind[i] = '''\\nUNWIND row.''' + fk[i] + ''' AS _''' + fk[i]\n",
    "            else:\n",
    "                query += '''\\nUNWIND row.''' + fk[i] + ''' AS _''' + fk[i]\n",
    "            prev_fk = ref_ids[i]\n",
    "\n",
    "        if len(uwind) > 0:\n",
    "            for i in range(len(fk)):\n",
    "                if i>0:\n",
    "                    query += '''\\nWITH distinct row, ''' + table.lower()\n",
    "                    query += uwind.get(i)\n",
    "                ref = _get_ref_node(table, ref_table)\n",
    "                query += '''\\nMATCH (''' + ref + ''':'''+ ref_table.capitalize() +''' {'''\n",
    "                query += ref_ids[i] + ''': _'''+fk[i]\n",
    "                query += '''})\\nMERGE ('''+table.lower()+''')-[:'''+ table.upper() + '''_''' + ref_table.upper() +''']->('''+ref+''')'''\n",
    "        else:\n",
    "            ref = _get_ref_node(table, ref_table)\n",
    "            query += '''\\nMATCH (''' + ref + ''':'''+ ref_table.capitalize() +''' {'''\n",
    "            first = True\n",
    "            for i in range(len(fk)):\n",
    "                if not first:\n",
    "                    query += ''','''\n",
    "                else:\n",
    "                    first = False\n",
    "                query += ref_ids[i] + ''': _'''+fk[i]\n",
    "            query += '''})\\nMERGE ('''+table.lower()+''')-[:'''+ table.upper() + '''_''' + ref_table.upper() +''']->('''+ref+''')'''\n",
    "\n",
    "        start = end\n",
    "\n",
    "    query += '''\\nRETURN count(*) AS total'''\n",
    "\n",
    "    df_logs = _add_row(df_logs, table, ref_tables=ref_tables, no_records=len(records), no_rels=len(ref_tables), no_edges=no_edges)\n",
    "        \n",
    "    if not commit:\n",
    "        print(query)\n",
    "    else:\n",
    "        neoConn.query(query, parameters = {'rows': records.to_dict('records')})    \n",
    "        \n",
    "    return df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e296ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ddl(c1, table):\n",
    "    q2 = \"SHOW CREATE TABLE %s;\" % table\n",
    "    c1.execute(q2)\n",
    "    result = c1.fetchone()\n",
    "    return list(result.values())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c82d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(c1, table):\n",
    "    ddl = get_ddl(c1, table)\n",
    "    \n",
    "    prog = re.compile('CREATE TABLE.*?`(.*).*?`\\s\\(', re.IGNORECASE)\n",
    "    table = prog.findall(ddl)[0]\n",
    "\n",
    "    prog = re.compile('PRIMARY KEY\\s\\S(.*)(?=\\))', re.IGNORECASE)\n",
    "    pri_key = None\n",
    "    if prog.findall(ddl):\n",
    "        pri_key = prog.findall(ddl)[0].replace('`', '')\n",
    "    else:\n",
    "        prog = re.compile('KEY.*?\\(`(.*).*?`\\)', re.IGNORECASE)\n",
    "        pri_key = prog.findall(ddl)[0].replace('`', '')\n",
    "\n",
    "    prog = re.compile('FOREIGN KEY.*?\\(`(.*).*?`\\)\\sREFERENCES', re.IGNORECASE)\n",
    "    for_keys = prog.findall(ddl)\n",
    "    for_keys = \",\".join(for_keys)\n",
    "\n",
    "    prog = re.compile('REFERENCES.*?`(.*).*?`\\s', re.IGNORECASE)\n",
    "    ref_tables = prog.findall(ddl)\n",
    "    ref_tables = \",\".join(ref_tables)\n",
    "\n",
    "    prog = re.compile('REFERENCES.*?\\(`(.*).*?`\\)', re.IGNORECASE)\n",
    "    ref_keys = prog.findall(ddl)\n",
    "    ref_keys = \",\".join(ref_keys)\n",
    "    \n",
    "    return {'table':table, 'pri_key':pri_key, 'for_keys': for_keys, 'ref_tables':ref_tables, 'ref_keys':ref_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd6bc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_out(data):\n",
    "    return len(data.split(','))        \n",
    "\n",
    "def _compute_in(key, unsorted_data):\n",
    "    counter = 0\n",
    "    for k, v in unsorted_data.items():\n",
    "        if k != key and key in v:\n",
    "            dependents = v.split(',')\n",
    "            for d in dependents:\n",
    "                if d.strip() == key:\n",
    "                    counter += 1\n",
    "    return counter\n",
    "    \n",
    "def _score_data(unsorted_data):\n",
    "    scores = {}\n",
    "    for key, data in unsorted_data.items():\n",
    "        out_elms = 0\n",
    "        in_elms = 0\n",
    "        if data.strip() == '':\n",
    "            scores[key] = 0\n",
    "        else:            \n",
    "            #compute: score = no.outgoung / no.incoming\n",
    "            out_elms = _compute_out(data)\n",
    "            in_elms = _compute_in(key, unsorted_data)\n",
    "            scores[key] = np.inf if in_elms == 0 else (out_elms/in_elms)\n",
    "        #print (\"Key [{}], Out[{}], In[{}], Score[{}]\".format(key, out_elms, in_elms, scores.get(key)))\n",
    "    \n",
    "    scores = dict(sorted(scores.items(), key=lambda item: item[1]))\n",
    "    #print(scores)\n",
    "    return scores\n",
    "    \n",
    "def _remove_best(unsorted_data, key, sorted_data, relations):\n",
    "    for k, v in unsorted_data.items():\n",
    "        if key in v:\n",
    "            deps = v.split(',')\n",
    "            dependents = deps.copy()\n",
    "            for d in deps:\n",
    "                if d.strip() == key:\n",
    "                    dependents.remove(d)\n",
    "\n",
    "                    #add the relation between this entry's key and the 'key', if record exists then append to it\n",
    "                    rels = relations.get(k)\n",
    "                    if rels:\n",
    "                        relations[k] = rels + ',' + key\n",
    "                    else:\n",
    "                        relations[k] = key\n",
    "            \n",
    "            #dependents = list(filter(lambda d: d.strip() != key, dependents))\n",
    "            unsorted_data[k] = ','.join(dependents)\n",
    "            \n",
    "    unsorted_data.pop(key, None)\n",
    "    \n",
    "def _remove_cyclic(unsorted_data, key, sorted_data, relations, cyclics):    \n",
    "    #1) add the 'key' as one of the cyclic dependencies\n",
    "    cyclics[key] = unsorted_data.get(key)\n",
    "    #2) remove from those depend on the 'key', record their relations to it, and finally remove the 'key'\n",
    "    _remove_best(unsorted_data, key, sorted_data, relations)\n",
    "    #3) finally, add the 'key' as one of the sorted keys\n",
    "    sorted_data.append(key)\n",
    "    \n",
    "def _sort(unsorted_data, sorted_data, relations, cyclics):\n",
    "    scores = _score_data(unsorted_data)\n",
    "        \n",
    "    best_key = list(scores.keys())[0]\n",
    "    best_val = list(scores.values())[0]\n",
    "    if best_val == 0:\n",
    "        #remove best[0] from unsorted_data\n",
    "        _remove_best(unsorted_data, best_key, sorted_data, relations)\n",
    "        sorted_data.append(best_key)\n",
    "    else:\n",
    "        print('CYCLIC detected!')\n",
    "        _remove_cyclic(unsorted_data, best_key, sorted_data, relations, cyclics)\n",
    "    \n",
    "    return unsorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3af6f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_row(df_logs, table, **kwargs):\n",
    "    idx = df_logs.index[df_logs['table']==table]\n",
    "    if len(idx):\n",
    "        idx = idx[0]\n",
    "        for key, value in kwargs.items():\n",
    "            if isinstance(value, list):   \n",
    "                value = ','.join(value)\n",
    "                \n",
    "            if key not in ['no_records', 'ref_tables'] and pd.notna(df_logs.iloc[idx][key]):\n",
    "            #if key not in (['no_records', 'ref_tables']) and df_logs.iloc[idx][key].any():\n",
    "                if isinstance(value, int):\n",
    "                    df_logs.at[idx, key] = df_logs.iloc[idx][key] + value\n",
    "                else:\n",
    "                    df_logs.at[idx, key] = df_logs.iloc[idx][key] + ',' + value\n",
    "            else:\n",
    "                df_logs.at[idx, key] = value\n",
    "    else:\n",
    "        df_logs = df_logs.append({'table':table}, ignore_index=True)\n",
    "    \n",
    "    return df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87f2140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _populate_graph(metas, sorted_data, relations, cyclics, df_logs, commit):\n",
    "    for data in sorted_data:\n",
    "        meta = metas[data]\n",
    "        table = meta['table']\n",
    "        df_logs = _add_row(df_logs, table)\n",
    "        rels = relations.get(table)\n",
    "        skip = cyclics.get(table)\n",
    "        if rels:\n",
    "            #joined\n",
    "            df_logs = generate_joined_graph(meta, skip, df_logs, commit)\n",
    "        else:\n",
    "            #single\n",
    "            #print(f'meta: {meta}')\n",
    "            #print(f'df_logs: {df_logs}')\n",
    "            df_logs = generate_single_graph(meta, df_logs, commit)\n",
    "    \n",
    "    #create relation for cyclic references\n",
    "    for table, refs in cyclics.items():\n",
    "        meta = metas[table]\n",
    "        df_logs = generate_edges(meta, refs, df_logs, commit)\n",
    "        \n",
    "    return df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b1c7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print(tables, metas, sorted_data, relations, cyclics):\n",
    "    \n",
    "    df_print1 = pd.DataFrame(columns=['table', 'ref_tables'])\n",
    "    sep = '---------------'\n",
    "    for table in tables:\n",
    "        m = metas[table]\n",
    "        ref_tables = m.get('ref_tables')\n",
    "        rels = ref_tables.split(',')\n",
    "        if ref_tables == '':\n",
    "            rels = None            \n",
    "        df_print1 = df_print1.append({'table':table, 'ref_tables':rels}, ignore_index=True)    \n",
    "    df_print1 = df_print1.append({'table':sep, 'ref_tables':sep}, ignore_index=True)\n",
    "    \n",
    "    df_print2 = pd.DataFrame(columns=['table', 'ref_tables'])\n",
    "    \n",
    "    for data in sorted_data:\n",
    "        meta = metas[data]\n",
    "        table = meta['table']\n",
    "        rs = relations.get(table)\n",
    "        rels = None\n",
    "        if rs:\n",
    "            rels = rs.split(',')\n",
    "        cs = cyclics.get(table)\n",
    "        skip = None\n",
    "        if cs:\n",
    "            skip = cs.split(',')\n",
    "        if skip and rels:\n",
    "            rels = [i for i in rels if i not in skip]\n",
    "        df_print2 = df_print2.append({'table':table, 'ref_tables':rels}, ignore_index=True)\n",
    "    df_print2 = df_print2.append({'table':sep, 'ref_tables':sep}, ignore_index=True)\n",
    "        \n",
    "    df_print3 = pd.DataFrame(columns=['table', 'ref_tables'])\n",
    "    for table, refs in cyclics.items():\n",
    "        df_print3 = df_print3.append({'table':table, 'ref_tables':refs}, ignore_index=True)\n",
    "    df_print3 = df_print3.append({'table':sep, 'ref_tables':sep}, ignore_index=True)\n",
    "    \n",
    "    df_print = df_print1.append(df_print2).append(df_print3)\n",
    "    display(df_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54b59139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_graph(df_logs, commit):\n",
    "    q1 = (\"SHOW TABLES FROM \" + schema)\n",
    "    c1 = connection.cursor(dictionary=True, buffered=True)\n",
    "    c1.execute(q1)\n",
    "\n",
    "    table_list = c1.fetchall()\n",
    "    tables = []\n",
    "    metas = {}\n",
    "    unsorted_data = {}\n",
    "    for entry in table_list:\n",
    "        _, table = entry.popitem()\n",
    "        tables.append(table)\n",
    "        meta = get_metadata(c1, table)\n",
    "        metas[table]=meta\n",
    "        unsorted_data[meta.get('table')] = meta.get('ref_tables')\n",
    "    \n",
    "    sorted_data = []\n",
    "    relations = {}\n",
    "    cyclics = {}\n",
    "    half_sort = dict(sorted(unsorted_data.items(), key=lambda item: item[1]))\n",
    "    while True:\n",
    "        half_sort = _sort(half_sort, sorted_data, relations, cyclics)\n",
    "        if (len(half_sort) == 0):\n",
    "            break\n",
    "\n",
    "    _print(tables, metas, sorted_data, relations, cyclics)\n",
    "    \n",
    "    return _populate_graph(metas, sorted_data, relations, cyclics, df_logs, commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "651c95ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cek_graph(df_logs):\n",
    "    for table in df_logs['table']:\n",
    "        query = f'MATCH (n:{table.capitalize()}) RETURN count(n) as total'\n",
    "        total = 0\n",
    "        idx = df_logs.index[df_logs['table']==table][0]\n",
    "\n",
    "        total = neoConn.query(query)\n",
    "        if total:\n",
    "            df_logs.at[idx,'no_nodes'] = total[0][0]\n",
    "\n",
    "            rt = df_logs.iloc[idx]['ref_tables']\n",
    "            if len(rt)>0:\n",
    "                ref_tables = rt.split(',')\n",
    "                ref_tables = list(dict.fromkeys(ref_tables))\n",
    "                total = 0\n",
    "                for rt in ref_tables:\n",
    "                    key = f'{table}_{rt}'.upper()\n",
    "                    query = f'MATCH p=()-[r:{key}]->() RETURN count(p) as total'\n",
    "                    tot = neoConn.query(query)[0][0]\n",
    "                    total = total + tot\n",
    "                df_logs.at[idx,'no_edges'] = total\n",
    "            \n",
    "    df_logs.loc['total']= df_logs.sum()\n",
    "    df_logs.loc[df_logs.index[-1], 'table'] = ''\n",
    "    df_logs.loc[df_logs.index[-1], 'ref_tables'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e38b3df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>ref_tables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>directors</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>directors_genres</td>\n",
       "      <td>[directors]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movies</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movies_directors</td>\n",
       "      <td>[movies, directors]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>movies_genres</td>\n",
       "      <td>[movies]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roles</td>\n",
       "      <td>[movies, actors]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>---------------</td>\n",
       "      <td>---------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>directors</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movies</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>directors_genres</td>\n",
       "      <td>[directors]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movies_genres</td>\n",
       "      <td>[movies]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roles</td>\n",
       "      <td>[actors, movies]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>movies_directors</td>\n",
       "      <td>[directors, movies]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>---------------</td>\n",
       "      <td>---------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---------------</td>\n",
       "      <td>---------------</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              table           ref_tables\n",
       "0            actors                 None\n",
       "1         directors                 None\n",
       "2  directors_genres          [directors]\n",
       "3            movies                 None\n",
       "4  movies_directors  [movies, directors]\n",
       "5     movies_genres             [movies]\n",
       "6             roles     [movies, actors]\n",
       "7   ---------------      ---------------\n",
       "0            actors                 None\n",
       "1         directors                 None\n",
       "2            movies                 None\n",
       "3  directors_genres          [directors]\n",
       "4     movies_genres             [movies]\n",
       "5             roles     [actors, movies]\n",
       "6  movies_directors  [directors, movies]\n",
       "7   ---------------      ---------------\n",
       "0   ---------------      ---------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===> Processing records for Table 'actors'\n",
      "\n",
      "\n",
      "===> Processing records for Table 'directors'\n",
      "\n",
      "\n",
      "===> Processing records for Table 'movies'\n",
      "\n",
      "\n",
      "===> Processing records for Table 'directors_genres'\n",
      "Processing reference Table 'directors' ...\n",
      "\n",
      "\n",
      "===> Processing records for Table 'movies_genres'\n",
      "Processing reference Table 'movies' ...\n",
      "\n",
      "\n",
      "===> Processing records for Table 'roles'\n",
      "Processing reference Table 'movies' ...\n",
      "Processing reference Table 'actors' ...\n",
      "\n",
      "\n",
      "===> Processing records for Table 'movies_directors'\n",
      "Processing reference Table 'movies' ...\n",
      "Processing reference Table 'directors' ...\n",
      "Execution time: 00:00:04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>ref_tables</th>\n",
       "      <th>no_records</th>\n",
       "      <th>no_rels</th>\n",
       "      <th>no_nodes</th>\n",
       "      <th>no_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actors</td>\n",
       "      <td></td>\n",
       "      <td>1907</td>\n",
       "      <td>0</td>\n",
       "      <td>1907</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>directors</td>\n",
       "      <td></td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movies</td>\n",
       "      <td></td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>directors_genres</td>\n",
       "      <td>directors</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movies_genres</td>\n",
       "      <td>movies</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roles</td>\n",
       "      <td>movies,actors</td>\n",
       "      <td>1989</td>\n",
       "      <td>2</td>\n",
       "      <td>1989</td>\n",
       "      <td>3978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>movies_directors</td>\n",
       "      <td>movies,directors</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4395</td>\n",
       "      <td>6</td>\n",
       "      <td>4395</td>\n",
       "      <td>4448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  table        ref_tables no_records no_rels no_nodes no_edges\n",
       "0                actors                         1907       0     1907      NaN\n",
       "1             directors                           34       0       34      NaN\n",
       "2                movies                           36       0       36      NaN\n",
       "3      directors_genres         directors        285       1      285      285\n",
       "4         movies_genres            movies        103       1      103      103\n",
       "5                 roles     movies,actors       1989       2     1989     3978\n",
       "6      movies_directors  movies,directors         41       2       41       82\n",
       "total                                           4395       6     4395     4448"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "commit = True\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "_clear_all(commit)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Execution time:', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "_sorted = []\n",
    "\n",
    "df_logs = pd.DataFrame(columns=['table', 'ref_tables', 'no_records', 'no_rels', 'no_nodes', 'no_edges'])\n",
    "df_logs = _generate_graph(df_logs, commit)\n",
    "\n",
    "cek_graph(df_logs)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Execution time:', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "df_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
